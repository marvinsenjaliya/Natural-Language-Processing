{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "#Natural Language Tool Kit\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "#to convert data into dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "#to clean data\n",
    "import re\n",
    "#for modeling \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>So good I am going to have to review this plac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>The chips and salsa were really good, the sals...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>This place is great!!!!!!!!!!!!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Mediocre food.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Once you get inside you'll be impressed with t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "795  So good I am going to have to review this plac...      1\n",
       "796  The chips and salsa were really good, the sals...      1\n",
       "797                  This place is great!!!!!!!!!!!!!!      1\n",
       "798                                     Mediocre food.      0\n",
       "799  Once you get inside you'll be impressed with t...      1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data from \n",
    "dataset = pd.read_csv(r\"E:\\bridgelabz\\Restaurant_Reviews (1).tsv\", sep='\\t', encoding='utf-8')\n",
    "#dataset.Review\n",
    "dataset = dataset.iloc[:800]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    False\n",
       "Liked     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Liked\n",
       "count  800.000000\n",
       "mean     0.565000\n",
       "std      0.496067\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning and proccesing \n",
    "#Remove Punctuations, Numbers\n",
    "#for remove stopword \n",
    "import re\n",
    "from nltk.corpus import stopwords   \n",
    "#for Stemming propose  \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "#Initialize empty List\n",
    "corpus = []\n",
    "for i in range(0, 800):\n",
    "    # column : \"Review\", row ith \n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    #converting all characters to lowercase\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "   #loop for stemming each word in string array at ith row\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    #rejoin all string array elements to create back into a string\n",
    "    review = ' '.join(review)\n",
    "    #append each string to create array of clean text\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow love place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tasti textur nasti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select menu great price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>good go review place twice herea tribut place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>chip salsa realli good salsa fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>place great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>mediocr food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>get insid impress place</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0                                       wow love place\n",
       "1                                           crust good\n",
       "2                                   tasti textur nasti\n",
       "3    stop late may bank holiday rick steve recommen...\n",
       "4                              select menu great price\n",
       "..                                                 ...\n",
       "795  good go review place twice herea tribut place ...\n",
       "796                 chip salsa realli good salsa fresh\n",
       "797                                        place great\n",
       "798                                       mediocr food\n",
       "799                            get insid impress place\n",
       "\n",
       "[800 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(corpus)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=10000, min_df=2,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "count_vect =  CountVectorizer(lowercase=True,stop_words='english',min_df=2,max_features = 10000 )\n",
    "print(count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 529)\t1\n",
      "  (0, 279)\t1\n",
      "  (0, 356)\t1\n",
      "  (1, 107)\t1\n",
      "  (1, 199)\t1\n",
      "  (2, 471)\t1\n",
      "  (2, 476)\t1\n",
      "  (2, 312)\t1\n",
      "  (3, 279)\t1\n",
      "  (3, 454)\t1\n",
      "  (3, 262)\t1\n",
      "  (3, 387)\t1\n",
      "  (4, 418)\t1\n",
      "  (4, 298)\t1\n",
      "  (4, 202)\t1\n",
      "  (4, 370)\t1\n",
      "  (5, 512)\t1\n",
      "  (5, 111)\t1\n",
      "  (5, 350)\t1\n",
      "  (6, 469)\t1\n",
      "  (6, 188)\t1\n",
      "  (7, 367)\t1\n",
      "  (7, 268)\t1\n",
      "  (7, 473)\t1\n",
      "  (7, 482)\t1\n",
      "  :\t:\n",
      "  (793, 85)\t1\n",
      "  (794, 426)\t1\n",
      "  (794, 209)\t1\n",
      "  (794, 318)\t1\n",
      "  (794, 17)\t1\n",
      "  (794, 114)\t1\n",
      "  (794, 525)\t1\n",
      "  (794, 285)\t1\n",
      "  (795, 356)\t2\n",
      "  (795, 199)\t1\n",
      "  (795, 318)\t1\n",
      "  (795, 394)\t1\n",
      "  (795, 157)\t1\n",
      "  (795, 495)\t1\n",
      "  (796, 199)\t1\n",
      "  (796, 188)\t1\n",
      "  (796, 383)\t1\n",
      "  (796, 83)\t1\n",
      "  (797, 356)\t1\n",
      "  (797, 202)\t1\n",
      "  (798, 187)\t1\n",
      "  (798, 295)\t1\n",
      "  (799, 356)\t1\n",
      "  (799, 248)\t1\n",
      "  (799, 243)\t1\n"
     ]
    }
   ],
   "source": [
    "x_count_vect = count_vect.fit_transform(corpus)\n",
    "print(x_count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 535)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_count_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolut',\n",
       " 'acknowledg',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'ago',\n",
       " 'alway',\n",
       " 'amaz',\n",
       " 'ambianc',\n",
       " 'ambienc',\n",
       " 'anoth',\n",
       " 'anyon',\n",
       " 'anytim',\n",
       " 'appet',\n",
       " 'area',\n",
       " 'arriv',\n",
       " 'ask',\n",
       " 'assur',\n",
       " 'ate',\n",
       " 'atmospher',\n",
       " 'attack',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'authent',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'awesom',\n",
       " 'babi',\n",
       " 'bachi',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bakeri',\n",
       " 'bar',\n",
       " 'bare',\n",
       " 'bartend',\n",
       " 'basic',\n",
       " 'bathroom',\n",
       " 'batter',\n",
       " 'bay',\n",
       " 'bean',\n",
       " 'beat',\n",
       " 'beauti',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'belli',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bisqu',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'black',\n",
       " 'bland',\n",
       " 'blow',\n",
       " 'boot',\n",
       " 'bowl',\n",
       " 'boy',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'brick',\n",
       " 'bring',\n",
       " 'brought',\n",
       " 'brunch',\n",
       " 'buffet',\n",
       " 'bunch',\n",
       " 'burger',\n",
       " 'busi',\n",
       " 'butter',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'came',\n",
       " 'car',\n",
       " 'care',\n",
       " 'cashier',\n",
       " 'char',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'chees',\n",
       " 'cheeseburg',\n",
       " 'chef',\n",
       " 'chewi',\n",
       " 'chicken',\n",
       " 'chines',\n",
       " 'chip',\n",
       " 'choos',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'close',\n",
       " 'cocktail',\n",
       " 'coffe',\n",
       " 'cold',\n",
       " 'combin',\n",
       " 'come',\n",
       " 'comfort',\n",
       " 'compani',\n",
       " 'complaint',\n",
       " 'complet',\n",
       " 'consid',\n",
       " 'conveni',\n",
       " 'cook',\n",
       " 'cool',\n",
       " 'coupl',\n",
       " 'cover',\n",
       " 'cow',\n",
       " 'cream',\n",
       " 'creami',\n",
       " 'crowd',\n",
       " 'crust',\n",
       " 'curri',\n",
       " 'custom',\n",
       " 'cute',\n",
       " 'damn',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'day',\n",
       " 'deal',\n",
       " 'decid',\n",
       " 'decor',\n",
       " 'definit',\n",
       " 'delici',\n",
       " 'delight',\n",
       " 'delish',\n",
       " 'deserv',\n",
       " 'dessert',\n",
       " 'die',\n",
       " 'differ',\n",
       " 'dine',\n",
       " 'dinner',\n",
       " 'dirt',\n",
       " 'dirti',\n",
       " 'disappoint',\n",
       " 'disgrac',\n",
       " 'disgust',\n",
       " 'dish',\n",
       " 'dog',\n",
       " 'dont',\n",
       " 'doubl',\n",
       " 'doubt',\n",
       " 'downtown',\n",
       " 'dress',\n",
       " 'dri',\n",
       " 'driest',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'duck',\n",
       " 'eat',\n",
       " 'eaten',\n",
       " 'edibl',\n",
       " 'egg',\n",
       " 'eggplant',\n",
       " 'els',\n",
       " 'elsewher',\n",
       " 'empti',\n",
       " 'end',\n",
       " 'enjoy',\n",
       " 'especi',\n",
       " 'establish',\n",
       " 'event',\n",
       " 'everi',\n",
       " 'everyon',\n",
       " 'everyth',\n",
       " 'excel',\n",
       " 'excus',\n",
       " 'expect',\n",
       " 'experi',\n",
       " 'experienc',\n",
       " 'extra',\n",
       " 'extrem',\n",
       " 'eye',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'famili',\n",
       " 'familiar',\n",
       " 'fan',\n",
       " 'fantast',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'favorit',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'filet',\n",
       " 'final',\n",
       " 'fine',\n",
       " 'fish',\n",
       " 'flavor',\n",
       " 'flower',\n",
       " 'folk',\n",
       " 'food',\n",
       " 'fresh',\n",
       " 'fri',\n",
       " 'friend',\n",
       " 'friendli',\n",
       " 'frozen',\n",
       " 'fun',\n",
       " 'gave',\n",
       " 'gener',\n",
       " 'given',\n",
       " 'glad',\n",
       " 'gold',\n",
       " 'good',\n",
       " 'got',\n",
       " 'greas',\n",
       " 'great',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'greet',\n",
       " 'grill',\n",
       " 'gross',\n",
       " 'group',\n",
       " 'guess',\n",
       " 'guest',\n",
       " 'guy',\n",
       " 'gyro',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'handl',\n",
       " 'happi',\n",
       " 'hard',\n",
       " 'hate',\n",
       " 'healthi',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'help',\n",
       " 'high',\n",
       " 'highli',\n",
       " 'hit',\n",
       " 'home',\n",
       " 'homemad',\n",
       " 'honest',\n",
       " 'hope',\n",
       " 'horribl',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hous',\n",
       " 'huge',\n",
       " 'hummu',\n",
       " 'husband',\n",
       " 'ice',\n",
       " 'ignor',\n",
       " 'imagin',\n",
       " 'immedi',\n",
       " 'impecc',\n",
       " 'impress',\n",
       " 'includ',\n",
       " 'incred',\n",
       " 'indian',\n",
       " 'inexpens',\n",
       " 'insid',\n",
       " 'insult',\n",
       " 'italian',\n",
       " 'job',\n",
       " 'joint',\n",
       " 'judg',\n",
       " 'kept',\n",
       " 'kid',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'known',\n",
       " 'lack',\n",
       " 'ladi',\n",
       " 'larg',\n",
       " 'late',\n",
       " 'later',\n",
       " 'leav',\n",
       " 'left',\n",
       " 'legit',\n",
       " 'let',\n",
       " 'like',\n",
       " 'list',\n",
       " 'liter',\n",
       " 'littl',\n",
       " 'live',\n",
       " 'lobster',\n",
       " 'locat',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'lover',\n",
       " 'lukewarm',\n",
       " 'lunch',\n",
       " 'main',\n",
       " 'make',\n",
       " 'mall',\n",
       " 'manag',\n",
       " 'mani',\n",
       " 'margarita',\n",
       " 'mari',\n",
       " 'mayb',\n",
       " 'mayo',\n",
       " 'meal',\n",
       " 'mean',\n",
       " 'meat',\n",
       " 'mediocr',\n",
       " 'meh',\n",
       " 'melt',\n",
       " 'menu',\n",
       " 'mexican',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'minut',\n",
       " 'miss',\n",
       " 'mistak',\n",
       " 'moist',\n",
       " 'mom',\n",
       " 'money',\n",
       " 'mood',\n",
       " 'mouth',\n",
       " 'multipl',\n",
       " 'music',\n",
       " 'nasti',\n",
       " 'need',\n",
       " 'neighborhood',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'nicest',\n",
       " 'night',\n",
       " 'non',\n",
       " 'note',\n",
       " 'noth',\n",
       " 'offer',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'old',\n",
       " 'omg',\n",
       " 'opportun',\n",
       " 'option',\n",
       " 'order',\n",
       " 'outsid',\n",
       " 'outstand',\n",
       " 'oven',\n",
       " 'overal',\n",
       " 'overpr',\n",
       " 'overwhelm',\n",
       " 'owner',\n",
       " 'pancak',\n",
       " 'paper',\n",
       " 'par',\n",
       " 'parti',\n",
       " 'pass',\n",
       " 'pasta',\n",
       " 'patio',\n",
       " 'pay',\n",
       " 'peopl',\n",
       " 'pepper',\n",
       " 'perfect',\n",
       " 'perfectli',\n",
       " 'person',\n",
       " 'pho',\n",
       " 'phoenix',\n",
       " 'pictur',\n",
       " 'piec',\n",
       " 'pita',\n",
       " 'pizza',\n",
       " 'place',\n",
       " 'play',\n",
       " 'pleas',\n",
       " 'pleasant',\n",
       " 'plu',\n",
       " 'point',\n",
       " 'poor',\n",
       " 'pop',\n",
       " 'pork',\n",
       " 'portion',\n",
       " 'possibl',\n",
       " 'potato',\n",
       " 'prepar',\n",
       " 'pretti',\n",
       " 'price',\n",
       " 'probabl',\n",
       " 'promis',\n",
       " 'provid',\n",
       " 'pull',\n",
       " 'qualiti',\n",
       " 'quick',\n",
       " 'quickli',\n",
       " 'quit',\n",
       " 'rare',\n",
       " 'rate',\n",
       " 'real',\n",
       " 'realiz',\n",
       " 'realli',\n",
       " 'reason',\n",
       " 'receiv',\n",
       " 'recent',\n",
       " 'recommend',\n",
       " 'red',\n",
       " 'regular',\n",
       " 'relax',\n",
       " 'remind',\n",
       " 'restaur',\n",
       " 'return',\n",
       " 'review',\n",
       " 'rice',\n",
       " 'right',\n",
       " 'roast',\n",
       " 'roll',\n",
       " 'rude',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'said',\n",
       " 'salad',\n",
       " 'salmon',\n",
       " 'salt',\n",
       " 'sandwich',\n",
       " 'sashimi',\n",
       " 'sat',\n",
       " 'satisfi',\n",
       " 'sauc',\n",
       " 'say',\n",
       " 'scallop',\n",
       " 'seafood',\n",
       " 'season',\n",
       " 'seat',\n",
       " 'second',\n",
       " 'seen',\n",
       " 'select',\n",
       " 'serv',\n",
       " 'server',\n",
       " 'servic',\n",
       " 'set',\n",
       " 'sever',\n",
       " 'shop',\n",
       " 'shrimp',\n",
       " 'sick',\n",
       " 'sign',\n",
       " 'similar',\n",
       " 'simpl',\n",
       " 'sinc',\n",
       " 'sit',\n",
       " 'slice',\n",
       " 'slow',\n",
       " 'small',\n",
       " 'smell',\n",
       " 'soggi',\n",
       " 'someon',\n",
       " 'someth',\n",
       " 'soon',\n",
       " 'soooo',\n",
       " 'sore',\n",
       " 'soup',\n",
       " 'special',\n",
       " 'spici',\n",
       " 'spot',\n",
       " 'staff',\n",
       " 'stale',\n",
       " 'star',\n",
       " 'station',\n",
       " 'stay',\n",
       " 'steak',\n",
       " 'step',\n",
       " 'stir',\n",
       " 'stop',\n",
       " 'strip',\n",
       " 'stuf',\n",
       " 'stuff',\n",
       " 'suck',\n",
       " 'sugari',\n",
       " 'super',\n",
       " 'sure',\n",
       " 'sushi',\n",
       " 'sweet',\n",
       " 'tabl',\n",
       " 'taco',\n",
       " 'talk',\n",
       " 'tapa',\n",
       " 'tartar',\n",
       " 'tast',\n",
       " 'tasteless',\n",
       " 'tasti',\n",
       " 'tea',\n",
       " 'tell',\n",
       " 'tender',\n",
       " 'terribl',\n",
       " 'textur',\n",
       " 'thai',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'thought',\n",
       " 'thumb',\n",
       " 'time',\n",
       " 'tip',\n",
       " 'toast',\n",
       " 'today',\n",
       " 'told',\n",
       " 'took',\n",
       " 'tot',\n",
       " 'total',\n",
       " 'touch',\n",
       " 'town',\n",
       " 'treat',\n",
       " 'tri',\n",
       " 'trip',\n",
       " 'twice',\n",
       " 'unbeliev',\n",
       " 'unfortun',\n",
       " 'unless',\n",
       " 'use',\n",
       " 'valley',\n",
       " 'valu',\n",
       " 'vega',\n",
       " 'vegetarian',\n",
       " 'ventur',\n",
       " 'vinegrett',\n",
       " 'visit',\n",
       " 'wait',\n",
       " 'waiter',\n",
       " 'waitress',\n",
       " 'walk',\n",
       " 'wall',\n",
       " 'want',\n",
       " 'warm',\n",
       " 'wast',\n",
       " 'watch',\n",
       " 'water',\n",
       " 'way',\n",
       " 'went',\n",
       " 'white',\n",
       " 'wife',\n",
       " 'wine',\n",
       " 'wing',\n",
       " 'wonder',\n",
       " 'word',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'wow',\n",
       " 'wrap',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'yummi',\n",
       " 'zero']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_names = count_vect.get_feature_names()\n",
    "x_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_count_name=pd.DataFrame(x_count_vect.toarray(), columns=x_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 535)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_count_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolut</th>\n",
       "      <th>acknowledg</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>ago</th>\n",
       "      <th>alway</th>\n",
       "      <th>amaz</th>\n",
       "      <th>ambianc</th>\n",
       "      <th>ambienc</th>\n",
       "      <th>anoth</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>wow</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yummi</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolut  acknowledg  actual  ad  ago  alway  amaz  ambianc  ambienc  anoth  \\\n",
       "0        0           0       0   0    0      0     0        0        0      0   \n",
       "1        0           0       0   0    0      0     0        0        0      0   \n",
       "2        0           0       0   0    0      0     0        0        0      0   \n",
       "3        0           0       0   0    0      0     0        0        0      0   \n",
       "4        0           0       0   0    0      0     0        0        0      0   \n",
       "\n",
       "   ...  work  world  worst  worth  wow  wrap  wrong  year  yummi  zero  \n",
       "0  ...     0      0      0      0    1     0      0     0      0     0  \n",
       "1  ...     0      0      0      0    0     0      0     0      0     0  \n",
       "2  ...     0      0      0      0    0     0      0     0      0     0  \n",
       "3  ...     0      0      0      0    0     0      0     0      0     0  \n",
       "4  ...     0      0      0      0    0     0      0     0      0     0  \n",
       "\n",
       "[5 rows x 535 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_count_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x_count_name\n",
    "y=dataset['Liked']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_count_name,y,test_size=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vector_classifier = SVC()\n",
    "support_vector_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=450,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier = RandomForestClassifier(n_estimators = 450)\n",
    "random_forest_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "decision_tree_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "svc_prediction = support_vector_classifier.predict(x_test)\n",
    "rfc_prediction = random_forest_classifier.predict(x_test)\n",
    "lr_prediction = logistic_regression.predict(x_test)\n",
    "decision_tree_prediction = decision_tree_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "76.875\n",
      "Random forest:\n",
      "77.5\n",
      "Logistic Regression:\n",
      "76.875\n",
      "Decision Tree:\n",
      "74.375\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "print(\"SVC\")\n",
    "print(accuracy_score(svc_prediction, y_test)*100)\n",
    "print(\"Random forest:\")\n",
    "print(accuracy_score(rfc_prediction, y_test)*100)\n",
    "print(\"Logistic Regression:\")\n",
    "print(accuracy_score(lr_prediction, y_test)*100)\n",
    "print(\"Decision Tree:\")\n",
    "print(accuracy_score(decision_tree_prediction, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Algorithm:\n",
      "[[54 10]\n",
      " [27 69]]\n",
      "Random forest Algorithm:\n",
      "[[65 20]\n",
      " [16 59]]\n",
      "Logistic Regression Algorithm:\n",
      "[[59 15]\n",
      " [22 64]]\n",
      "Decision Tree Algorithm:\n",
      "[[59 19]\n",
      " [22 60]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "print(\"SVC Algorithm:\")\n",
    "print(confusion_matrix(svc_prediction, y_test))\n",
    "print(\"Random forest Algorithm:\")\n",
    "print(confusion_matrix(rfc_prediction, y_test))\n",
    "print(\"Logistic Regression Algorithm:\")\n",
    "print(confusion_matrix(lr_prediction, y_test))\n",
    "print(\"Decision Tree Algorithm:\")\n",
    "print(confusion_matrix(decision_tree_prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.74        64\n",
      "           1       0.87      0.72      0.79        96\n",
      "\n",
      "    accuracy                           0.77       160\n",
      "   macro avg       0.77      0.78      0.77       160\n",
      "weighted avg       0.79      0.77      0.77       160\n",
      "\n",
      "Random forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78        85\n",
      "           1       0.75      0.79      0.77        75\n",
      "\n",
      "    accuracy                           0.78       160\n",
      "   macro avg       0.77      0.78      0.77       160\n",
      "weighted avg       0.78      0.78      0.78       160\n",
      "\n",
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        74\n",
      "           1       0.81      0.74      0.78        86\n",
      "\n",
      "    accuracy                           0.77       160\n",
      "   macro avg       0.77      0.77      0.77       160\n",
      "weighted avg       0.77      0.77      0.77       160\n",
      "\n",
      "Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74        78\n",
      "           1       0.76      0.73      0.75        82\n",
      "\n",
      "    accuracy                           0.74       160\n",
      "   macro avg       0.74      0.74      0.74       160\n",
      "weighted avg       0.74      0.74      0.74       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(\"Support Vector:\")\n",
    "print(classification_report(svc_prediction, y_test))\n",
    "print(\"Random forest:\")\n",
    "print(classification_report(rfc_prediction, y_test))\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(lr_prediction, y_test))\n",
    "print(\"Decision Tree:\")\n",
    "print(classification_report(decision_tree_prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "def review_prediction(review):\n",
    "    new_corpus = []\n",
    "    review = re.sub('[^a-zA-Z]', ' ' ,review)\n",
    "    #converting all characters to lowercase\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "   #loop for stemming each word in string array at ith row\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    #rejoin all string array elements to create back into a string\n",
    "    review = ' '.join(review)\n",
    "    #append each string to create array of clean text\n",
    "    corpus.append(review)\n",
    "    count_vect = CountVectorizer(lowercase=True,stop_words='english',min_df=2,max_features = 10000)\n",
    "    x_count_vect = count_vect.fit_transform(corpus + new_corpus).toarray()\n",
    "    X = x_count_vect[-1].reshape(1, -1)\n",
    "    prediction = logistic_regression.predict(X)\n",
    "    if prediction == 1:\n",
    "        return \"Positive Review\"\n",
    "    else:\n",
    "        return \"Negative Review\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service of this restaurant is worst\n",
      "Negative Review\n"
     ]
    }
   ],
   "source": [
    "print(review_prediction(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food quality is too good\n",
      "Positive Review\n"
     ]
    }
   ],
   "source": [
    "print(review_prediction(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
